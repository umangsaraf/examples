{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "15yLeJZw8ncp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare the Environment"
      ]
    },
    {
      "metadata": {
        "id": "b2uU_hgOtGur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f490e97-3902-4ebe-e1c6-f5166cc8b6a8"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
            "Requirement already satisfied: torch_nightly in /usr/local/lib/python3.6/dist-packages (1.0.0.dev20181011)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSsB1s-p4kPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09363dc9-a617-41aa-f61e-1c44efcae94b"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ceshine/examples.git pytorch_examples"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pytorch_examples' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vtJtfZas4oS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "153c2cd0-cb8f-4de7-c22d-67e3ad706086"
      },
      "cell_type": "code",
      "source": [
        "%cd pytorch_examples/word_language_model\n",
        "%ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pytorch_examples/word_language_model\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/        lm_model.pt   model.py      requirements.txt\n",
            "data.py      main.py       \u001b[01;34m__pycache__\u001b[0m/  train_new.log\n",
            "generate.py  model_new.pt  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yAAdydfL6vcs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload the trained model (from notebook 01_Training.ipynb):"
      ]
    },
    {
      "metadata": {
        "id": "PpgaP3x1icla",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "9hByUNAB6F6_",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "02a93afb-8cc1-45cc-bc27-6bb05c1f9260"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-40f6f1ad-0502-4728-b078-da136ed1ef00\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-40f6f1ad-0502-4728-b078-da136ed1ef00\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "M5fre8JFEO8R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above did not work for me (because I constantly failed to download the entire file). Using gsutil instead here:"
      ]
    },
    {
      "metadata": {
        "id": "vNhKUTtMEXZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74ceda78-abfe-4fb7-d278-b62bf0ed35d8"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'personal-project-196600'\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5GIVuGa7Ei4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5e591b04-690d-4e73-cbd9-2e28112624eb"
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp  gs://ceshine-colab-tmp/lm_model.pt lm_model.pt"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://ceshine-colab-tmp/lm_model.pt...\n",
            "\\ [1 files][108.5 MiB/108.5 MiB]                                                \n",
            "Operation completed over 1 objects/108.5 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CZAw4xjq9wSH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import libraries, functions and classes:"
      ]
    },
    {
      "metadata": {
        "id": "PX8bxlu_7wYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from model import RNNModel\n",
        "from data import Dictionary, Corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A5FDZG9y46of",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Dictionary"
      ]
    },
    {
      "metadata": {
        "id": "AOUPtIdJ-0qC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "711f133f-b466-48ff-ae07-56ebd84368dd"
      },
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"./data/wikitext-2\"\n",
        "corpus = Corpus(DATA_PATH)\n",
        "\n",
        "print(\"Number of tokens:\")\n",
        "print(\"Train: \", len(corpus.train))\n",
        "print(\"Valid: \", len(corpus.valid))\n",
        "print(\"Test:  \", len(corpus.test))\n",
        "\n",
        "print(\"Vocabulary size:\", len(corpus.dictionary.idx2word))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokens:\n",
            "Train:  2075677\n",
            "Valid:  216347\n",
            "Test:   244102\n",
            "Vocabulary size: 33278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FU4dIZ68_pxl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Model"
      ]
    },
    {
      "metadata": {
        "id": "Yr54aXIS_PZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "# model = model.RNNModel(\n",
        "#     \"LSTM\", len(corpus.dictionary), 650,\n",
        "#     650, 2, 0.5, True\n",
        "# ).to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QWwNQyPAfSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"lm_model.pt\", 'rb') as f:\n",
        "    model = torch.load(f, map_location='cpu')\n",
        "model = model.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYerbMO0FEwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6d25897e-e2e4-4948-8794-333c98d09324"
      },
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNModel(\n",
              "  (drop): Dropout(p=0.5)\n",
              "  (encoder): Embedding(33278, 650)\n",
              "  (rnn): LSTM(650, 650, num_layers=2, dropout=0.5)\n",
              "  (decoder): Linear(in_features=650, out_features=33278, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "metadata": {
        "id": "oJM06o9eFKpt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate with Test Documents"
      ]
    },
    {
      "metadata": {
        "id": "z7EuOn6idH_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculate the Perplexity of the Test Predictions\n",
        "To confirm we have loaded the correct model."
      ]
    },
    {
      "metadata": {
        "id": "eFjgGcqcbLk6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0d45ab36-fbdb-43df-93d2-707b9e8933e5"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "BPTT = 50\n",
        "CRITERION = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(DEVICE)\n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(BPTT, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    hidden = model.init_hidden(10)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, BPTT):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            output, hidden = model(data, hidden)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * CRITERION(output_flat, targets).item()\n",
        "            hidden = repackage_hidden(hidden)\n",
        "    return total_loss / len(data_source)\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "    \n",
        "test_data = batchify(corpus.test, 10)\n",
        "loss = evaluate(test_data)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 55s, sys: 1.68 s, total: 5min 57s\n",
            "Wall time: 5min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mt5E12qghArC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13da0e7d-d3ce-44af-910d-d0a3a4265d90"
      },
      "cell_type": "code",
      "source": [
        "loss, np.exp(loss)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.486460813329338, 88.8065859480267)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "metadata": {
        "id": "mRWnZR7oM9DO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check the Next Word Predictions"
      ]
    },
    {
      "metadata": {
        "id": "UYzjsoksGn59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11a12226-12d2-4dcd-86ca-85de4ba11849"
      },
      "cell_type": "code",
      "source": [
        "test_tokens = corpus.test.numpy()\n",
        "eos_pos = np.where(test_tokens == corpus.dictionary.word2idx[\"<eos>\"])[0]\n",
        "print(\"Number of lines in test:\", len(eos_pos))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of lines in test: 2891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJRJZL-SF943",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9df5a937-86fa-4dae-aafa-65f87b123870"
      },
      "cell_type": "code",
      "source": [
        "# A random line from test dataset\n",
        "print(\" \".join([corpus.dictionary.idx2word[c] for c in test_tokens[eos_pos[28]+1:eos_pos[29]]]))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The An <unk> Rebellion began in December <unk> , and was not completely suppressed for almost eight years . It caused enormous disruption to Chinese society : the census of 754 recorded 52 @.@ 9 million people , but ten years later , the census counted just 16 @.@ 9 million , the remainder having been displaced or killed . During this time , Du Fu led a largely itinerant life <unk> by wars , associated <unk> and imperial <unk> . This period of <unk> was the making of Du Fu as a poet : Even Shan Chou has written that , \" What he saw around him — the lives of his family , neighbors , and strangers – what he heard , and what he hoped for or feared from the progress of various campaigns — these became the enduring themes of his poetry \" . Even when he learned of the death of his youngest child , he turned to the suffering of others in his poetry instead of dwelling upon his own <unk> . Du Fu wrote :\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Lsf43zAFKDT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_chunk(start, end):\n",
        "    token_tensor = corpus.test[eos_pos[start]+1:eos_pos[end]]\n",
        "    hidden = model.init_hidden(1)\n",
        "    with torch.no_grad():\n",
        "        targets = token_tensor[1:]\n",
        "        output, hidden = model(token_tensor.unsqueeze(1), hidden)\n",
        "        output_flat = output.squeeze(1)\n",
        "        loss = CRITERION(output_flat[:-1], targets).item()\n",
        "    \n",
        "    sorted_idx = np.argsort(output_flat.numpy(), 1)\n",
        "    preds = []\n",
        "    for i in range(1, 4):\n",
        "        preds.append(list(map(lambda x: corpus.dictionary.idx2word[x], sorted_idx[:, -i])))\n",
        "    # preds = list(map(lambda x: itos[x], np.argmax(logits.data.cpu().numpy(), 1)))\n",
        "    return (\n",
        "        loss,\n",
        "        pd.DataFrame({\n",
        "            \"orig\": [corpus.dictionary.idx2word[x] for x in token_tensor.numpy()] + [\" \"], \n",
        "            \"pred_1\": [\"\"] + preds[0], \"pred_2\": [\"\"] + preds[1], \"pred_3\": [\"\"] + preds[2]\n",
        "        })\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwgGIiA8MwmO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's try using only one line:"
      ]
    },
    {
      "metadata": {
        "id": "_gbOxcgBLSv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1616
        },
        "outputId": "813549de-18af-4f60-85dd-ae5f9c1ef2ef"
      },
      "cell_type": "code",
      "source": [
        "loss, df = eval_chunk(28, 29)\n",
        "print(\"Loss:\", np.exp(loss))\n",
        "df.iloc[-50:]"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 163.91555818335866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orig</th>\n",
              "      <th>pred_1</th>\n",
              "      <th>pred_2</th>\n",
              "      <th>pred_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>progress</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>world</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>various</td>\n",
              "      <td>the</td>\n",
              "      <td>his</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>campaigns</td>\n",
              "      <td>people</td>\n",
              "      <td>things</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>—</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>these</td>\n",
              "      <td>and</td>\n",
              "      <td>the</td>\n",
              "      <td>\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>became</td>\n",
              "      <td>are</td>\n",
              "      <td>were</td>\n",
              "      <td>people</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>the</td>\n",
              "      <td>more</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>enduring</td>\n",
              "      <td>most</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>first</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>themes</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>subject</td>\n",
              "      <td>thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>in</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>his</td>\n",
              "      <td>the</td>\n",
              "      <td>his</td>\n",
              "      <td>all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>poetry</td>\n",
              "      <td>life</td>\n",
              "      <td>own</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>\"</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Even</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>The</td>\n",
              "      <td>He</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>when</td>\n",
              "      <td>though</td>\n",
              "      <td>in</td>\n",
              "      <td>after</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>he</td>\n",
              "      <td>he</td>\n",
              "      <td>the</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>learned</td>\n",
              "      <td>was</td>\n",
              "      <td>had</td>\n",
              "      <td>died</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>that</td>\n",
              "      <td>about</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>his</td>\n",
              "      <td>her</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>death</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>book</td>\n",
              "      <td>death</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>,</td>\n",
              "      <td>he</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>his</td>\n",
              "      <td>his</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>youngest</td>\n",
              "      <td>wife</td>\n",
              "      <td>father</td>\n",
              "      <td>brother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>child</td>\n",
              "      <td>wife</td>\n",
              "      <td>son</td>\n",
              "      <td>brother</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>in</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>he</td>\n",
              "      <td>he</td>\n",
              "      <td>the</td>\n",
              "      <td>John</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>turned</td>\n",
              "      <td>was</td>\n",
              "      <td>had</td>\n",
              "      <td>wrote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>to</td>\n",
              "      <td>out</td>\n",
              "      <td>to</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>suffering</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>public</td>\n",
              "      <td>house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>and</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>others</td>\n",
              "      <td>his</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>in</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>his</td>\n",
              "      <td>the</td>\n",
              "      <td>his</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>poetry</td>\n",
              "      <td>life</td>\n",
              "      <td>own</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>instead</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>dwelling</td>\n",
              "      <td>his</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>upon</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>his</td>\n",
              "      <td>his</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>own</td>\n",
              "      <td>death</td>\n",
              "      <td>arrival</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>death</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>Du</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>The</td>\n",
              "      <td>He</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>Fu</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>Braun</td>\n",
              "      <td>Jarl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>wrote</td>\n",
              "      <td>,</td>\n",
              "      <td>was</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>:</td>\n",
              "      <td>a</td>\n",
              "      <td>the</td>\n",
              "      <td>that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td></td>\n",
              "      <td>\"</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          orig  pred_1   pred_2   pred_3\n",
              "133   progress   <unk>    world     time\n",
              "134         of      of        .        ,\n",
              "135    various     the      his        a\n",
              "136  campaigns  people   things    <unk>\n",
              "137          —       .        ,        \"\n",
              "138      these     and      the        \"\n",
              "139     became     are     were   people\n",
              "140        the       a      the     more\n",
              "141   enduring    most    <unk>    first\n",
              "142     themes   <unk>  subject    thing\n",
              "143         of      of       in        .\n",
              "144        his     the      his      all\n",
              "145     poetry    life      own    <unk>\n",
              "146          \"       .        ,      and\n",
              "147          .       .        ,      and\n",
              "148       Even   <eos>      The       He\n",
              "149       when  though       in    after\n",
              "150         he      he      the        ,\n",
              "151    learned     was      had     died\n",
              "152         of      of     that    about\n",
              "153        the     the      his      her\n",
              "154      death   <unk>     book    death\n",
              "155         of      of        ,       he\n",
              "156        his     his      the        a\n",
              "157   youngest    wife   father  brother\n",
              "158      child    wife      son  brother\n",
              "159          ,       ,       in      and\n",
              "160         he      he      the     John\n",
              "161     turned     was      had    wrote\n",
              "162         to     out       to     down\n",
              "163        the     the        a    <unk>\n",
              "164  suffering   <unk>   public    house\n",
              "165         of      of      and        ,\n",
              "166     others     his      the        a\n",
              "167         in       ,      and        .\n",
              "168        his     the      his        a\n",
              "169     poetry    life      own    <unk>\n",
              "170    instead       .        ,      and\n",
              "171         of      of        .        ,\n",
              "172   dwelling     his      the        a\n",
              "173       upon       .        ,      and\n",
              "174        his     his      the        a\n",
              "175        own   death  arrival    <unk>\n",
              "176      <unk>   death    <unk>     work\n",
              "177          .       .        ,      and\n",
              "178         Du   <eos>      The       He\n",
              "179         Fu   <unk>    Braun     Jarl\n",
              "180      wrote       ,      was      and\n",
              "181          :       a      the     that\n",
              "182                  \"    <eos>        '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "metadata": {
        "id": "5NT3hejgMzcH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now try providing more context:"
      ]
    },
    {
      "metadata": {
        "id": "hIw64ToYMUJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1616
        },
        "outputId": "f8b76fb2-dad3-4eb4-cd47-a419ef260f34"
      },
      "cell_type": "code",
      "source": [
        "loss, df = eval_chunk(28, 34)\n",
        "print(\"Loss:\", np.exp(loss))\n",
        "df.iloc[-50:]"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 104.32415212207026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orig</th>\n",
              "      <th>pred_1</th>\n",
              "      <th>pred_2</th>\n",
              "      <th>pred_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>in</td>\n",
              "      <td>to</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>summer</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>middle</td>\n",
              "      <td>morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>and</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>1918</td>\n",
              "      <td>the</td>\n",
              "      <td>1916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>;</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>this</td>\n",
              "      <td>he</td>\n",
              "      <td>the</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>has</td>\n",
              "      <td>was</td>\n",
              "      <td>time</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>traditionally</td>\n",
              "      <td>been</td>\n",
              "      <td>a</td>\n",
              "      <td>also</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>been</td>\n",
              "      <td>been</td>\n",
              "      <td>occurred</td>\n",
              "      <td>come</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>ascribed</td>\n",
              "      <td>described</td>\n",
              "      <td>a</td>\n",
              "      <td>used</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>by</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>famine</td>\n",
              "      <td>the</td>\n",
              "      <td>his</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>,</td>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>but</td>\n",
              "      <td>and</td>\n",
              "      <td>but</td>\n",
              "      <td>as</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>he</td>\n",
              "      <td>it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>believes</td>\n",
              "      <td>,</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>that</td>\n",
              "      <td>that</td>\n",
              "      <td>the</td>\n",
              "      <td>he</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>frustration</td>\n",
              "      <td>the</td>\n",
              "      <td>he</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>is</td>\n",
              "      <td>in</td>\n",
              "      <td>from</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>a</td>\n",
              "      <td>not</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>more</td>\n",
              "      <td>\"</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>likely</td>\n",
              "      <td>important</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>powerful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>reason</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>part</td>\n",
              "      <td>subject</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>.</td>\n",
              "      <td>for</td>\n",
              "      <td>to</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>He</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>He</td>\n",
              "      <td>The</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>next</td>\n",
              "      <td>was</td>\n",
              "      <td>also</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>spent</td>\n",
              "      <td>,</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>around</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>six</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>weeks</td>\n",
              "      <td>years</td>\n",
              "      <td>months</td>\n",
              "      <td>days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>in</td>\n",
              "      <td>,</td>\n",
              "      <td>of</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>his</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>(</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>now</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>a</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>,</td>\n",
              "      <td>)</td>\n",
              "      <td>,</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>Gansu</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>the</td>\n",
              "      <td>now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>province</td>\n",
              "      <td>,</td>\n",
              "      <td>)</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>)</td>\n",
              "      <td>)</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>and</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>where</td>\n",
              "      <td>and</td>\n",
              "      <td>where</td>\n",
              "      <td>but</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>he</td>\n",
              "      <td>he</td>\n",
              "      <td>the</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>wrote</td>\n",
              "      <td>was</td>\n",
              "      <td>had</td>\n",
              "      <td>died</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>more</td>\n",
              "      <td>to</td>\n",
              "      <td>a</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>than</td>\n",
              "      <td>than</td>\n",
              "      <td>of</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>sixty</td>\n",
              "      <td>a</td>\n",
              "      <td>one</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>poems</td>\n",
              "      <td>years</td>\n",
              "      <td>@-@</td>\n",
              "      <td>men</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>.</td>\n",
              "      <td>,</td>\n",
              "      <td>.</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td></td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>He</td>\n",
              "      <td>The</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              orig     pred_1    pred_2    pred_3\n",
              "489             in         to       the         a\n",
              "490            the        the         a       his\n",
              "491         summer      <unk>    middle   morning\n",
              "492             of         of       and         ,\n",
              "493          <unk>       1918       the      1916\n",
              "494              ;          ,       and         .\n",
              "495           this         he       the       his\n",
              "496            has        was      time        is\n",
              "497  traditionally       been         a      also\n",
              "498           been       been  occurred      come\n",
              "499       ascribed  described         a      used\n",
              "500             to         to        by       the\n",
              "501         famine        the       his         a\n",
              "502              ,          .         ,       and\n",
              "503            but        and       but        as\n",
              "504          <unk>        the        he        it\n",
              "505       believes          ,     <unk>       the\n",
              "506           that       that       the        he\n",
              "507    frustration        the        he       his\n",
              "508             is         in      from       was\n",
              "509              a        not       the         a\n",
              "510           more          \"     <unk>     great\n",
              "511         likely  important     <unk>  powerful\n",
              "512         reason      <unk>      part   subject\n",
              "513              .        for        to         .\n",
              "514             He      <eos>        He       The\n",
              "515           next        was      also        is\n",
              "516          spent          ,     <unk>       was\n",
              "517         around        the         a       his\n",
              "518            six        the         a       his\n",
              "519          weeks      years    months      days\n",
              "520             in          ,        of        in\n",
              "521          <unk>        the       his         a\n",
              "522              (          ,       and         .\n",
              "523            now      <unk>         a       and\n",
              "524          <unk>      <unk>       the         a\n",
              "525              ,          )         ,     <unk>\n",
              "526          Gansu      <unk>       the       now\n",
              "527       province          ,         )       and\n",
              "528              )          )         ,       and\n",
              "529              ,          ,       and         .\n",
              "530          where        and     where       but\n",
              "531             he         he       the       his\n",
              "532          wrote        was       had      died\n",
              "533           more         to         a       the\n",
              "534           than       than        of     <unk>\n",
              "535          sixty          a       one       the\n",
              "536          poems      years       @-@       men\n",
              "537              .          ,         .       and\n",
              "538                     <eos>        He       The"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "metadata": {
        "id": "n1J3aRTNNCtJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Try to Generate Texts"
      ]
    },
    {
      "metadata": {
        "id": "5vZ1f4HVUHRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e813046-6f40-4626-f68d-6abc8e1dbbb0"
      },
      "cell_type": "code",
      "source": [
        "UNK = corpus.dictionary.word2idx[\"<unk>\"]\n",
        "UNK"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "metadata": {
        "id": "RcC-UdUZVrD2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Greedy Selection"
      ]
    },
    {
      "metadata": {
        "id": "A-1CnFWVNGTX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text_from_chunk(start, end, target_length=20):\n",
        "    \"\"\"Greedy selection of the next token.\"\"\"\n",
        "    token_tensor = corpus.test[eos_pos[start]+1:eos_pos[end]]\n",
        "    return generate_text_from_tensor(token_tensor, target_length)\n",
        "    \n",
        "def generate_text_from_tensor(token_tensor, target_length):\n",
        "    hidden = model.init_hidden(1)\n",
        "    output, hidden = model(token_tensor.unsqueeze(1), hidden)\n",
        "    index = output[-1, -0, :].argmax()\n",
        "    res = [index.numpy()]\n",
        "    with torch.no_grad():    \n",
        "        for i in range(target_length):\n",
        "            output, hidden = model(index.unsqueeze(0).unsqueeze(0), hidden)\n",
        "            index = output[-1, 0, ].argmax()\n",
        "            res.append(index.numpy())\n",
        "    return [\n",
        "        [\n",
        "           corpus.dictionary.idx2word[x] for x in arr            \n",
        "        ] for arr in (token_tensor.numpy(), res)\n",
        "    ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QceMDqccPTNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e4a60054-a406-4e24-cbdc-cecf13d0782e"
      },
      "cell_type": "code",
      "source": [
        "context, new_texts = generate_text_from_chunk(28, 29)\n",
        "print(\" \".join(context[-10:]))\n",
        "print(\" \".join(new_texts))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dwelling upon his own <unk> . Du Fu wrote :\n",
            "\" I 'm not going to be a <unk> , and I am not going to be a <unk> . \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L_eca7VhS76z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e5b88ba5-295a-42ec-91f9-27d78b917065"
      },
      "cell_type": "code",
      "source": [
        "context, new_texts = generate_text_from_chunk(28, 38)\n",
        "print(\" \".join(context[-10:]))\n",
        "print(\" \".join(new_texts))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fu financially and employed him as his unofficial secretary .\n",
            "The Latin chronicler John C. <unk> also described him as his \" liberal @-@ confident \" . He described them\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A7LXS_pnVvnY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Sampling from the Predicted Distribution with a Temeperature Knob"
      ]
    },
    {
      "metadata": {
        "id": "kSBkyqogV-M7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text_from_chunk(start, end, target_length=20, temperature=1.0):\n",
        "    token_tensor = corpus.test[eos_pos[start]+1:eos_pos[end]]\n",
        "    return generate_text_from_tensor(token_tensor, target_length, temperature)\n",
        "    \n",
        "\n",
        "def generate_text_from_tensor(token_tensor, target_length, temperature):\n",
        "    \"\"\"Sampling from the softmax distribution.\"\"\"    \n",
        "    hidden = model.init_hidden(1)\n",
        "    _, hidden = model(token_tensor[:-1].unsqueeze(1), hidden)\n",
        "    input_tensor = torch.zeros((1, 1)).long().to(DEVICE)\n",
        "    input_tensor[0, 0].fill_(token_tensor[-1])\n",
        "    res = []\n",
        "    with torch.no_grad():    \n",
        "        for i in range(target_length):            \n",
        "            output, hidden = model(input_tensor, hidden)\n",
        "            word_weights = output.squeeze().div(temperature).exp()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            input_tensor[0, 0].fill_(word_idx)\n",
        "            res.append(word_idx.item())\n",
        "    return [\n",
        "        [\n",
        "           corpus.dictionary.idx2word[x] for x in arr            \n",
        "        ] for arr in (token_tensor.numpy(), res)\n",
        "    ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpZVvNGpXHxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4861f329-bb55-45d4-b5ea-2d822065194f"
      },
      "cell_type": "code",
      "source": [
        "context, new_texts = generate_text_from_chunk(28, 33, target_length=50)\n",
        "print(\" \".join(context[-10:]))\n",
        "for i in range(0, len(new_texts), 10):\n",
        "    print(\" \".join(new_texts[i:i+10]))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bring more papers to pile higher on my desk .\n",
            "\" <unk> ( two ) and Cristina 's army in\n",
            "<unk> where all historians discovered that the German sniper was\n",
            "still <unk> from and one out of the Sisler children\n",
            ". A brother <unk> , the friend of Richard ,\n",
            "senior of the island , was therefore procured in the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uataLNWWYqK8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text_from_texts(texts, target_length=20, temperature=1.0):\n",
        "    \"\"\"texts needs to be tokens seperated by space characters.\"\"\"\n",
        "    token_tensor = torch.LongTensor([\n",
        "        corpus.dictionary.word2idx[x] for x in texts.split(\" \")\n",
        "    ]).to(DEVICE)\n",
        "    return generate_text_from_tensor(token_tensor, target_length, temperature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4DNHQVUQjE2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "577a9287-dc35-42bb-ccca-8d8f17fc5332"
      },
      "cell_type": "code",
      "source": [
        "context, new_texts =  generate_text_from_texts(\"In the fall of 1944 , <unk> enrolled at the University of Michigan . The United Press syndicate\", target_length=100)\n",
        "print(\" \".join(context[-10:]))\n",
        "for i in range(0, len(new_texts), 10):\n",
        "    print(\" \".join(new_texts[i:i+10]))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at the University of Michigan . The United Press syndicate\n",
            "and officials was interpreted by the searing complaints being used\n",
            "as the musician by another mixed review , but expressed\n",
            "concern that the laws would be found out in the\n",
            "United States and during a transmission control of the same\n",
            "second landscapes . Lisa that he managed to visit the\n",
            "relationship with Carey and Marvel 's general president for food\n",
            "was \" desperate and looking , based on their own\n",
            "wing . \" Asked in this , the company was\n",
            "told by the US Bureau of Education , who decided\n",
            ", and eventually admitted to the 1920s , and \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S4jHkK4NjaFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}